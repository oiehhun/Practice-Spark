{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 9강. Spark cluster & word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Map Reduce용 Spark API 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### key와 value로 데이터를 구분해보자\n",
    "- Spark는 주어진 Rdd의 row가 가지고 있는 첫번째 column을 key로 인식함\n",
    "- 대부분의 Key가 필요한 함수들은 접미어로 Key를 가지고 있음\n",
    " + ex> sortByKey, reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/03 19:24:10 WARN Utils: Your hostname, itaehun-ui-MacBookAir.local resolves to a loopback address: 127.0.0.1; using 172.24.96.75 instead (on interface en0)\n",
      "24/04/03 19:24:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/03 19:24:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/homebrew/Cellar/apache-spark/3.5.1/libexec')\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"myAppName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\"/>\n",
    "- map<br>\n",
    " + 주어진 rdd에 func로 맵 변형을 수행한다<br><br>\n",
    " \n",
    "- flatMap<br>\n",
    " + 주어진 rdd에 func으로 맵 변형을 주고 배열을 하나 벗겨 flatten한다<br><br>\n",
    "- reduceByKey<br>\n",
    " + 주어진 rdd를 key를 기준으로 collect후 주어진 func을 수행<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 3, 1, 2, 2, 4]\n",
      "\n",
      "[(1, 2), (1, 3), (1, 2), (2, 4)]\n",
      "\n",
      "[1, 2, 1, 3, 1, 2, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "#중첩된 형태의 rdd를 하나의 row 단위로 풀어 줄 수 있는 명령, 대단히 중요한 명령\n",
    "rdd = sc.parallelize([(1, 2), (1, 3), (1, 2), (2, 4)]) # 앞은 key, 뒤는 value\n",
    "print(rdd.flatMap(lambda x:x).collect())\n",
    "print()\n",
    "\n",
    "rdd = sc.parallelize([(1, 2), (1, 3), (1, 2), (2, 4)])\n",
    "print(rdd.map(lambda x:x).collect())\n",
    "print()\n",
    "\n",
    "#중첩된 정도에 따라 row로 풀리는 단위가 다름\n",
    "rdd = sc.parallelize([((1, 2), (1, 3)), ((1, 2), (2, 4))])\n",
    "print(rdd.flatMap(lambda x:x).flatMap(lambda x:x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', ',', 'd', 'e', ',', 'f']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([\"a\", \"b\", \"c,d\", \"e,f\"])\n",
    "rdd.flatMap(lambda x:x).collect()\n",
    "# rdd.map(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x:x.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'cd', 'ef']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x:x.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 12), (2, 4), (10, 3), (3, 7)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduceByKey를 이용하여 key 별로 reduce를 수행할 수 있음\n",
    "rdd = sc.parallelize([(1, 2), (1, 3), (1, 2), (2, 4), (1, 5), (3,2), (3,5), (10,1), (10, 2)])\n",
    "\n",
    "#1 -> (1,2) (1,3) ( 1,2) (1,5) => [2, 3, 2, 5]\n",
    "#2 -> (2,4) => [4]\n",
    "#3 -> (3,2) (3,5) => [2, 5]\n",
    "#10 -> (10,1) (10,2) => [1, 2]\n",
    "rdd.reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, <pyspark.resultiterable.ResultIterable object at 0x1095f6940>), (2, <pyspark.resultiterable.ResultIterable object at 0x1095223a0>)]\n",
      "1 [2, 3, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "#groupBy와 유사한 groupByKey동작도 존재함\n",
    "#reduceByKey는 함수로 처리된 하나의 결과값을 남겨두지만\n",
    "#groupByKey는 모든 원소를 보유하고 순회할 수 있음\n",
    "rdd = sc.parallelize([(1, 2), (1, 3), (1, 2), (2, 4), (1, 5)])\n",
    "grouped = rdd.groupByKey() # 메모리를 많이 잡아먹기 때문에 reduceByKey를 사용함\n",
    "print(grouped.collect())\n",
    "\n",
    "#grouped data중 1이 key인 group 데이터를 추출\n",
    "a, b = grouped.collect()\n",
    "print(a[0], list(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(False, <pyspark.resultiterable.ResultIterable object at 0x1096118b0>), (True, <pyspark.resultiterable.ResultIterable object at 0x109522e50>)]\n",
      "[1, 3, 5, 7]\n",
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "#key를 group 기준으로 임의로 만들어 준 뒤 groupByKey나 reduceByKey를 돌리는 것이 일반적\n",
    "#다음 데이터에 짝수, 홀수의 기준으로 key를 분리한뒤 groupByKey로 각 원소를 출력해보자\n",
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8])\n",
    "rdd = rdd.map(lambda x:(x % 2 ==0, x))\n",
    "print ( rdd.groupByKey().collect() )\n",
    "\n",
    "a, b = rdd.groupByKey().collect()\n",
    "print (list(a[1]))\n",
    "print (list(b[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\"/>\n",
    "- mapValues(func)<br>\n",
    " + 주어진 rdd를 순회하면서 key와 value 중 value 부분에 func을 적용<br><br>\n",
    "- flatMapValues(func)<br>\n",
    " + 주어진 rdd를 flat 동작을 value 기준으로 수행하면서 key와 합쳐서 생성해냄<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('c', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapValues는 key, value로 나눠진 데이터에 대하여 value 쪽만 function으로 컨트롤 가능\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "rdd = rdd.map(lambda x: (x, 0)) # (a, 0), (b, 0), (c, 0)\n",
    "rdd = rdd.mapValues(lambda x:x+1) # ((a, 1), (b, 1), (c, 1))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('c', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sc.parallelize([\"a\", \"b\", \"c\"]).map(lambda x: (x, 0))  # ('a', 0), ('b', 0), ('c', 0)\n",
    "b = a.map(lambda x: (x[0], x[1]+1)) # ('a', 1) ('b', 1)\n",
    "b.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', (1, 1)), ('b', (1, 1)), ('c', (1, 1))]\n",
      "[('a', 1), ('a', 1), ('b', 1), ('b', 1), ('c', 1), ('c', 1)]\n"
     ]
    }
   ],
   "source": [
    "#flatMapValues를 이용하여 key에 대하여 각 value들을 모두 새로운 기준의 row로 분리 가능\n",
    "print( rdd.mapValues(lambda x:(x, x)).collect() )\n",
    "print( rdd.mapValues(lambda x:(x, x)).flatMapValues(lambda x:x).collect() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 위키 피디아 파일을 읽어보자\n",
    "- Spark는 plain text에 대한 read/write 및 rdd 전환을 지원함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/itaehun/python/빅실무\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print ( os.getcwd() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This page was last edited on 11 June 2018, at 19:08 (UTC).\n",
      "Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
      "Privacy policyAbout WikipediaDisclaimersContact WikipediaDevelopersCookie statementMobile viewWikimedia Foundation Powered by MediaWiki\n"
     ]
    }
   ],
   "source": [
    "with open('./data/wiki_wordcount.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[-3:]:\n",
    "        print (line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\"/>\n",
    "- sparkContext.textFile(filePath, partitionNum = None)<br>\n",
    " + 파일을 읽어옴, 주어진 개수로 파티션을 분리할 수 있음\n",
    " + wildcard 및 정규 표현식 사용 가능<br><br>\n",
    "- rdd.saveAsTextFile(path, compressionCodecClass=None)<br>\n",
    " + 주어진 rdd를 plain text로 저장함, compressionCodecClass를 통하여 압축방법을 지정가능<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#wild card를 지정하여 파일을 읽을 수 있음\n",
    "print(type(sc.textFile('./data/wiki_wordcount.txt')))\n",
    "print(sc.textFile('./data/wiki_wordcount.txt').getNumPartitions())\n",
    "print(sc.textFile('./data/wiki_*.txt', 3).getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Word count',\n",
       " 'From Wikipedia, the free encyclopedia',\n",
       " 'Jump to navigationJump to search',\n",
       " 'The word count is the number of words in a document or passage of text. Word counting may be needed when a text is required to stay within certain numbers of words. This may particularly be the case in academia, legal proceedings, journalism and advertising. Word count is commonly used by translators to determine the price for the translation job. Word counts may also be used to calculate measures of readability and to measure typing and reading speeds (usually in words per minute). When converting character counts to words, a measure of 5 or 6 characters to a word is generally used for English.[1]',\n",
       " '',\n",
       " '',\n",
       " 'Contents',\n",
       " '1\\tDetails and variations of definition',\n",
       " '2\\tSoftware',\n",
       " '3\\tIn fiction',\n",
       " '4\\tIn non-fiction',\n",
       " '5\\tSee also',\n",
       " '6\\tReferences',\n",
       " '7\\tSources',\n",
       " 'Details and variations of definition',\n",
       " '',\n",
       " 'This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2014) (Learn how and when to remove this template message)',\n",
       " 'Variations in the operational definitions of how to count the words can occur (namely, what \"counts as\" a word, and which words \"don\\'t count\" toward the total). However, especially since the advent of widespread word processing, there is a broad consensus on these operational definitions (and hence the bottom-line integer result). The consensus is to accept the text segmentation rules generally found in most word processing software (including how word boundaries are determined, which depends on how word dividers are defined). The first trait of that definition is that a space (any of various whitespace characters, such as a \"regular\" word space, an em space, or a tab character) is a word divider. Usually a hyphen or a slash is, too. Different word counting programs may give varying results, depending on the text segmentation rule details, and on whether words outside the main text (such as footnotes, endnotes, or hidden text) are counted. But the behavior of most major word processing applications is broadly similar.',\n",
       " '',\n",
       " 'However, during the era when school assignments were done in handwriting or with typewriters, the rules for these definitions often differed from today\\'s consensus. Most importantly, many students were drilled on the rule that \"certain words don\\'t count\", usually articles (namely, \"a\", \"an\", \"the\"), but sometimes also others, such as conjunctions (for example, \"and\", \"or\", \"but\") and some prepositions (usually \"to\", \"of\"). Hyphenated permanent compounds such as \"follow-up\" (noun) or \"long-term\" (adjective) were counted as one word. To save the time and effort of counting word-by-word, often a rule of thumb for the average number of words per line was used, such as 10 words per line. These \"rules\" have fallen by the wayside in the word processing era; the \"word count\" feature of such software (which follows the text segmentation rules mentioned earlier) is now the standard arbiter, because it is largely consistent (across documents and applications) and because it is fast, effortless, and costless (already included with the application).',\n",
       " '',\n",
       " 'As for which sections of a document \"count\" toward the total (such as footnotes, endnotes, abstracts, reference lists and bibliographies, tables, figure captions, hidden text), the person in charge (teacher, client) can define their choice, and users (students, workers) can simply select (or exclude) the elements accordingly, and watch the word count automatically update.',\n",
       " '',\n",
       " 'Software',\n",
       " 'Modern web browsers support word counting via extensions, via a JavaScript bookmarklet,[2] or a script [3] that is hosted in a website. Most word processors can also count words. Unix-like systems include a program, wc, specifically for word counting. There are a wide variety of word counting tools available online.',\n",
       " '',\n",
       " 'As explained earlier, different word counting programs may give varying results, depending on the text segmentation rule details. The exact number of words often is not a strict requirement, thus the variation is acceptable.',\n",
       " '',\n",
       " 'In fiction',\n",
       " 'Novelist Jane Smiley suggests that length is an important quality of the novel.[4] However, novels can vary tremendously in length; Smiley lists novels as typically being between 100,000 and 175,000 words,[5] while National Novel Writing Month requires its novels to be at least 50,000 words. There are no firm rules: for example, the boundary between a novella and a novel is arbitrary and a literary work may be difficult to categorise.[6] But while the length of a novel is to a large extent up to its writer,[7] lengths may also vary by subgenre; many chapter books for children start at a length of about 16,000 words,[8] and a typical mystery novel might be in the 60,000 to 80,000 word range while a thriller could be well over 100,000 words.[9]',\n",
       " '',\n",
       " 'The Science Fiction and Fantasy Writers of America specifies word lengths for each category of its Nebula award categories:[10]',\n",
       " '',\n",
       " 'Classification\\tWord count',\n",
       " 'Novel\\t40,000 words or over',\n",
       " 'Novella\\t17,500 to 39,999 words',\n",
       " 'Novelette\\t7,500 to 17,499 words',\n",
       " 'Short story\\tunder 7,500 words',\n",
       " 'In non-fiction',\n",
       " 'The acceptable length of an academic dissertation varies greatly, dependent predominantly on the subject. Numerous American universities limit Ph.D. dissertations to 100,000 words, barring special permission for exceeding this limit.[11]',\n",
       " '',\n",
       " 'See also',\n",
       " 'Flash fiction',\n",
       " 'List of longest novels',\n",
       " 'Twitterature',\n",
       " 'Word lists by frequency',\n",
       " 'References',\n",
       " ' The Science Fiction and Fantasy Writers of America suggest 6 chars to a word',\n",
       " ' E.g., Tavory, Ran. \"Word Count Bookmarklet\". Marklets.com. Retrieved March 3, 2013.',\n",
       " ' E.g., Word Counter. \"Word Count Tool\". Retrieved March 6, 2014.',\n",
       " ' Smiley, Jane. 2005. Thirteen Ways of Looking at the Novel. NY: Alfred A. Knopf, p. 14.',\n",
       " ' Smiley, 2005, p. 15.',\n",
       " ' Edge, Tom, \"Does Size Matter?\" The Guardian (UK), Booksblog, Nov. 2, 2006. http://www.guardian.co.uk/books/booksblog/2006/nov/02/doessizematter',\n",
       " ' Quindlen, Anna (September 23, 2002), \"Writers on Writing: The Eye of the Reporter, the Heart of the Novelist\", New York Times, A novelist doesn\\'t write to space, of course; 80,000 words, 100,000, it is up to the writer to say when the story is done..',\n",
       " \" Lamb, Nancy, Crafting Stories for Children. Cincinnati: Writer's Digest Books, p. 24\",\n",
       " ' Thurston, Carol (August 3, 1997), \"Agents give writers the book on what\\'s hot and what\\'s not\", Austin American-Statesman, no one wants more than 60-80,000 words in a mystery, 110,000 for a thriller.',\n",
       " ' SFWA Awards FAQ, Science Fiction and Fantasy Writers of America as follows:',\n",
       " ' Dunleavy, Patrick (2003), Authoring a PhD, Palgrave Macmillan, p. 46, ISBN 978-1-4039-1191-9.',\n",
       " 'Sources',\n",
       " 'DeRocher, James E.; Miron, Murray S.; Patten, Sam M.; Pratt, Charles C. (1973), The Counting of Words: A Review of the History, Techniques and Theory of Word Counts with Annotated Bibliography (PDF), Syracuse University Research Corporation, p. 302, ED098814.',\n",
       " 'Rothman, Chuck (2005), Word Counts: What Is a Word?, Science Fiction Writers of America. An article on various word count methods in fiction publishing.',\n",
       " 'Michaels, Melisa (2005), Focusing on the Wrong Things, Science Fiction Writers of America, archived from the original on April 17, 2009 An article on the relative importance of various word count methods in fiction publishing.',\n",
       " 'Categories: Word processorsBook terminologyWriting',\n",
       " 'Navigation menu',\n",
       " 'Not logged inTalkContributionsCreate accountLog inArticleTalkReadEditView historySearch',\n",
       " '',\n",
       " 'Search Wikipedia',\n",
       " 'Main page',\n",
       " 'Contents',\n",
       " 'Featured content',\n",
       " 'Current events',\n",
       " 'Random article',\n",
       " 'Donate to Wikipedia',\n",
       " 'Wikipedia store',\n",
       " 'Interaction',\n",
       " 'Help',\n",
       " 'About Wikipedia',\n",
       " 'Community portal',\n",
       " 'Recent changes',\n",
       " 'Contact page',\n",
       " 'Tools',\n",
       " 'What links here',\n",
       " 'Related changes',\n",
       " 'Upload file',\n",
       " 'Special pages',\n",
       " 'Permanent link',\n",
       " 'Page information',\n",
       " 'Wikidata item',\n",
       " 'Cite this page',\n",
       " 'Print/export',\n",
       " 'Create a book',\n",
       " 'Download as PDF',\n",
       " 'Printable version',\n",
       " '',\n",
       " 'Languages',\n",
       " 'Bân-lâm-gú',\n",
       " 'فارسی',\n",
       " 'Edit links',\n",
       " 'This page was last edited on 11 June 2018, at 19:08 (UTC).',\n",
       " 'Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.',\n",
       " 'Privacy policyAbout WikipediaDisclaimersContact WikipediaDevelopersCookie statementMobile viewWikimedia Foundation Powered by MediaWiki']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('./data/wiki_wordcount.txt').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### word count를 작성하여 보자\n",
    "- 1. text파일을 rdd로 변환\n",
    "- 2. map을 이용하여 word 기준으로 분리\n",
    "- 3. flatMap을 이용하여 한 단어기준으로 row 추출\n",
    "- 4. 각 word에 1이라는 count를 value에 부여\n",
    "- 5. reduce를 실행하여 각 word 별 count를 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1),\n",
       " ('Word', 1),\n",
       " ('count', 1),\n",
       " ('From', 1),\n",
       " ('Wikipedia,', 1),\n",
       " ('the', 1),\n",
       " ('free', 1),\n",
       " ('encyclopedia', 1),\n",
       " ('Jump', 1),\n",
       " ('to', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map 부분을 완성해보자\n",
    "rdd = sc.textFile('./data/wiki_wordcount.txt')\n",
    "rdd1 = rdd.map(lambda line:line.split(' '))\n",
    "rdd2 = rdd1.flatMap(lambda x:x)\n",
    "rdd3 = rdd2.map(lambda word:(word, 1))\n",
    "rdd3.collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('فارسی', 1),\n",
       " ('you', 1),\n",
       " ('writers', 1),\n",
       " ('writer,[7]', 1),\n",
       " ('writer', 1),\n",
       " ('write', 1),\n",
       " ('workers)', 1),\n",
       " ('work', 1),\n",
       " ('words.[9]', 1),\n",
       " ('words.', 3)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce 부분을 완성한 후 10개를 출력\n",
    "rdd4 = rdd3.reduceByKey(lambda x,y:x+y)\n",
    "rdd4.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#결과를 저장\n",
    "rdd4.saveAsTextFile('./data/word_count_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 기존에 사용했던 rdd를 빠르게 재사용해보자\n",
    "- 일반적으로 rdd는 action이 수행될때 관련된 transformation 동작을 다시 수행함\n",
    "- 적은 데이터와 짧은 lineage를 가지고 있는 rdd는 결과가 빠르게 나오지만 데이터가 크거나 lineage가 크다면 결과까지 상당한 시간이 소요 될 수 있음\n",
    "- 2번 이상의 재사용성을 가진 rdd는 memory나 storage에 저장하고 다시 재활용이 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\"/>\n",
    "- rdd.persist(storageLevel)<br>\n",
    " + rdd를 memory나 hdd에 저장함<br>\n",
    " + storageLevel은 pyspark.StorageLevel에서 결정할 수 있음<br><br>\n",
    "- rdd.unpersist()<br>\n",
    " + 저장되었던 rdd를 memory나 hdd에서 해제함\n",
    "- rdd.cache()<br>\n",
    " + rdd 결과를 memory에 저장함, rdd.persist(pyspark.StorageLevel.MEMORY_ONLY)와 같은 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 384615), (11, 384615), (10, 384615)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(5000000))\n",
    "rdd1 = rdd.map(lambda x:(x%13, 1))\n",
    "rdd2 = rdd1.reduceByKey(lambda a,b:a+b)\n",
    "rdd2.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 384615), (11, 384615), (10, 384615)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rdd_cache = rdd2.cache()\n",
    "rdd_persist = rdd2.persist(pyspark.StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 384615), (11, 384615), (10, 384615)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_cache.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 384615), (11, 384615), (10, 384615)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_persist.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/03 20:19:35 WARN BlockManager: Asked to remove block rdd_89_5, which does not exist\n"
     ]
    }
   ],
   "source": [
    "rdd_cache = rdd_cache.unpersist()\n",
    "rdd_persist = rdd_persist.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "314.391px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
